{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0b20f5-3dc2-48b7-a950-cebfe32efe2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "bronze_table = \"workspace.applied_research_bronze.hr_bronze_data\"\n",
    "silver_table = \"workspace.applied_research_silver.hr_silver_data_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38dbdea5-88c5-4da5-addb-19f370fb54f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not spark.catalog.tableExists(silver_table):\n",
    "    print(\"Silver table not found. Creating it\")\n",
    "\n",
    "    bronze_schema_df = spark.table(bronze_table).limit(0)\n",
    "\n",
    "    empty_silver_df = (\n",
    "        bronze_schema_df\n",
    "            .drop(\"snapshot_date\", \"time_in_company\", \"previous_job_level\",\n",
    "                  \"last_raise_year\", \"month\", \"promotion_count\")\n",
    "            .withColumnsRenamed({\n",
    "                \"Employee_ID\": \"employee_id\",\n",
    "                \"Full_Name\": \"full_name\",\n",
    "                \"Department\": \"department\",\n",
    "                \"Job_Title\": \"job_title\",\n",
    "                \"Hire_Date\": \"hire_date\",\n",
    "                \"Location\": \"location\",\n",
    "                \"Performance_Rating\": \"performance_rating\",\n",
    "                \"Experience_Years\": \"experience_years\",\n",
    "                \"Status\": \"status\",\n",
    "                \"Work_Mode\": \"work_mode\",\n",
    "                \"Annual_Salary\": \"annual_salary\",\n",
    "                \"Job_Level\": \"job_level\"\n",
    "            })\n",
    "            .select(\n",
    "                \"employee_id\", \"full_name\", \"department\", \"job_title\", \"hire_date\",\n",
    "                \"location\", \"performance_rating\", \"experience_years\",\n",
    "                \"status\", \"work_mode\", \"annual_salary\", \"job_level\",\n",
    "                \"ingestion_timestamp\"\n",
    "            )\n",
    "            .withColumn(\"data_hash\", f.lit(None).cast(\"string\"))\n",
    "            .withColumn(\"start_effectivity_date\", f.lit(None).cast(\"timestamp\"))\n",
    "            .withColumn(\"end_effectivity_date\", f.lit(None).cast(\"timestamp\"))\n",
    "            .withColumn(\"is_active\", f.lit(False))\n",
    "    )\n",
    "\n",
    "    empty_silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(silver_table)\n",
    "    print(\"Silver table created.\")\n",
    "\n",
    "silver_tabler = DeltaTable.forName(spark, silver_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1e82dfa-f210-443c-a3b6-0f89be5b3ab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "timestamps = (\n",
    "    spark.table(bronze_table)\n",
    "         .select(\"ingestion_timestamp\")\n",
    "         .distinct()\n",
    "         .orderBy(\"ingestion_timestamp\")\n",
    "         .collect()\n",
    ")\n",
    "\n",
    "timestamp_list = [row[\"ingestion_timestamp\"] for row in timestamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80145e52-9033-42bc-a163-82a52ce6381c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tracked_columns = [\n",
    "    \"employee_id\", \"full_name\", \"department\", \"job_title\",\n",
    "    \"location\", \"performance_rating\", \"status\", \"work_mode\", \"job_level\"\n",
    "]\n",
    "\n",
    "def prepare_dataframe(df):\n",
    "    \"\"\"Applies column cleaning, renaming, ordering and SCD2 metadata.\"\"\"\n",
    "    df = df.drop(\"snapshot_date\", \"time_in_company\", \"previous_job_level\",\n",
    "                 \"last_raise_year\", \"month\", \"promotion_count\")\n",
    "\n",
    "    df = df.withColumnsRenamed({\n",
    "        \"Employee_ID\": \"employee_id\",\n",
    "        \"Full_Name\": \"full_name\",\n",
    "        \"Department\": \"department\",\n",
    "        \"Job_Title\": \"job_title\",\n",
    "        \"Hire_Date\": \"hire_date\",\n",
    "        \"Location\": \"location\",\n",
    "        \"Performance_Rating\": \"performance_rating\",\n",
    "        \"Experience_Years\": \"experience_years\",\n",
    "        \"Status\": \"status\",\n",
    "        \"Work_Mode\": \"work_mode\",\n",
    "        \"Annual_Salary\": \"annual_salary\",\n",
    "        \"Job_Level\": \"job_level\"\n",
    "    })\n",
    "\n",
    "    df = df.select(\n",
    "        \"employee_id\", \"full_name\", \"department\", \"job_title\", \"hire_date\",\n",
    "        \"location\", \"performance_rating\", \"experience_years\",\n",
    "        \"status\", \"work_mode\", \"annual_salary\", \"job_level\",\n",
    "        \"ingestion_timestamp\"\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"data_hash\", f.sha2(f.concat_ws(\"_\", *tracked_columns), 256)) \\\n",
    "           .withColumn(\"start_effectivity_date\", f.col(\"ingestion_timestamp\")) \\\n",
    "           .withColumn(\"end_effectivity_date\", f.lit(None).cast(\"timestamp\")) \\\n",
    "           .withColumn(\"is_active\", f.lit(True))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54e360fe-cf3a-4e24-928d-d1811c7e2492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for ts in timestamp_list:\n",
    "\n",
    "    bronze_batch = spark.sql(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {bronze_table}\n",
    "        WHERE ingestion_timestamp = '{ts}'\n",
    "    \"\"\")\n",
    "\n",
    "    df = prepare_dataframe(bronze_batch)\n",
    "    \n",
    "\n",
    "    current_silver_df = silver_tabler.toDF().filter(f.col(\"is_active\") == True)\n",
    "\n",
    "    changed_df = (\n",
    "        df.alias(\"bronze\")\n",
    "          .join(current_silver_df.alias(\"silver\"), on=\"employee_id\")\n",
    "          .filter(f.col(\"bronze.data_hash\") != f.col(\"silver.data_hash\"))\n",
    "          .select(\"bronze.*\")\n",
    "    )\n",
    "\n",
    "    new_employees_df = (\n",
    "        df.alias(\"bronze\")\n",
    "          .join(current_silver_df.select(\"employee_id\").alias(\"silver\"),\n",
    "                on=\"employee_id\", how=\"left_anti\")\n",
    "    )\n",
    "\n",
    "    departed_employees_df = (\n",
    "        current_silver_df.alias(\"silver\")\n",
    "            .join(df.select(\"employee_id\").alias(\"bronze\"),\n",
    "                  on=\"employee_id\", how=\"left_anti\")\n",
    "    )\n",
    "\n",
    "    changed_records = changed_df.unionByName(departed_employees_df).distinct()\n",
    "    new_records = changed_df.unionByName(new_employees_df)\n",
    "\n",
    "    if changed_records.count() > 0:\n",
    "        silver_tabler.alias(\"silver\").merge(\n",
    "            changed_records.alias(\"bronze\"),\n",
    "            \"silver.employee_id = bronze.employee_id AND silver.is_active = True\"\n",
    "        ).whenMatchedUpdate(set={\n",
    "            \"is_active\": f.lit(False),\n",
    "            \"end_effectivity_date\": f.current_timestamp()\n",
    "        }).execute()\n",
    "\n",
    "    if new_records.count() > 0:\n",
    "        silver_tabler.alias(\"silver\").merge(\n",
    "            new_records.alias(\"bronze\"),\n",
    "            \"silver.employee_id = bronze.employee_id AND silver.is_active = True\"\n",
    "        ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b82c043-cc78-45ee-86cd-e6be05585652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test = spark.read.table(\"workspace.applied_research_silver.hr_silver_data_test\")\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d0cc94-1b11-4c1c-a25a-1cb275ae91a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test.groupBy('ingestion_timestamp') \\\n",
    "  .pivot('is_active') \\\n",
    "  .count() \\\n",
    "  .orderBy('ingestion_timestamp') \\\n",
    "  .show(100)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_silver_auto_input",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
